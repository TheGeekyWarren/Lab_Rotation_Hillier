{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a40da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this code is used to find out the number of frames detected as faces by the human face analyser model.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda329f-efda-445e-a58c-1a87f8ad2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Long.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e02146-f2c2-4a3f-bad5-9b86e1b40e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/Humanfacenoface_try.mp4'\n",
    "dsv = deeplabcut.DownSampleVideo(start_file, width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda2adf-dc33-4685-97cb-8aa71535dacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "model = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(dsv)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "start_sec = 0\n",
    "end_sec = 0\n",
    "\n",
    "start_frame = int(start_sec * fps)\n",
    "end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# Define the initial frame index and label list\n",
    "frame_index = start_frame\n",
    "labels = []\n",
    "check = 0\n",
    "tot_yes = 0\n",
    "frame_id=[]\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "#text_file.write(labels)\n",
    "check = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Loop through the frames in the video\n",
    "while True: \n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    check = 0\n",
    "    \n",
    "    # Check if the frame was successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "         \n",
    "    # Resize the frame to a smaller size (for faster processing)\n",
    "    small_frame = cv2.resize(frame, (300, 300))\n",
    "    \n",
    "    # Preprocess the frame for input to the neural network\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    # Pass the blob through the neural network to detect faces\n",
    "    model.setInput(blob) \n",
    "    detections = model.forward()\n",
    "    \n",
    "    # Loop through the detections and draw rectangles around the monkey faces\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.6:  # Only show faces with high confidence+\n",
    "            check = 1; \n",
    "            frame_id.append(frame_index)\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    labels.append([frame_index, check])#This code appends a list of labels (i.e., whether a face is present in each frame) with the current frame index and the value of check. If a face is detected in the current frame (i.e., check is 1), then tot_yes is incremented by 1\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "    if check:\n",
    "        tot_yes += 1\n",
    "    # Show the frame with monkey faces detected\n",
    "    cv2.imshow(\"Monkey faces\", frame)\n",
    "    frame_index += 1\n",
    "    # Wait for a key press\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "#This code appends two lists to the labels list. \n",
    "labels.append([tot_yes, (frame_index-tot_yes)]) #this list contains the total number of frames with faces (tot_yes) and the total number of frames without faces (frame_index-tot_yes). \n",
    "text_file = open(\"text_fileFacehumands.csv\", \"w\") #opens a new file called \"text_fileFacehumands.csv\" in write mode (`\"w\"`). This file will be used to store the face detection information.\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])#Textracts the coordinates of the bounding box around each detected face in the current frame (`detections[0, 0, i, 3:7]`) and scales them according to the dimensions of the frame (`* np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])`). The resulting `box` variable contains the x and y coordinates of the top-left corner of the bounding box and its width and height.\n",
    "\n",
    "\n",
    "labelled = pd.DataFrame(labels, columns = ['Frame_id','Face'])#creates a new Pandas DataFrame called `labelled` from the `labels` list. The DataFrame has two columns named \"Frame_id\" and \"Face\" that correspond to the two values stored in each list within the `labels` list.\n",
    "\n",
    "labelled.to_csv(\"text_fileFacehumands.csv\")#saves the `labelled` DataFrame as a CSV file with the filename \"text_fileFacehumands.csv\"\n",
    "# Release the video file and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43e243-743f-43e3-97e0-9371dd25d04a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_frame = pd.read_csv('text_fileFaceGC.csv', header = 0, index_col=0)\n",
    "k = df_frame.loc[len(df_frame) -1].Frame_id\n",
    "l = k.strip('][').split(', ')\n",
    "x = [int(i) for i in l]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fb9b0-157e-463e-8d29-0400eb364f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_frame.drop(df_frame.tail(2).index,inplace=True)\n",
    "frame_ids = []\n",
    "for i in df_frame.Frame_id:\n",
    "    print(df_frame.loc[i].loc['Face?'])\n",
    "        #frame_ids.append(i)\n",
    "        \n",
    "#frame_id = frame_ids[:-2]\n",
    "#frame_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d9b93-8d3f-46ff-afdf-60bbc79461c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cropping video and Gamma correction\n",
    "\n",
    "# # Load the video file\n",
    "# video = cv2.VideoCapture(dsv)\n",
    "\n",
    "# # Get the frame rate and total number of frames\n",
    "# fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# #*********************************************\n",
    "\n",
    "# # Set the start and end points to crop out\n",
    "# start_sec = 10  # Crop out the first x seconds\n",
    "# end_sec = 10 # Crop out the last y seconds\n",
    "\n",
    "# #Set gamma correction value\n",
    "# gamma = 2\n",
    "\n",
    "# #**********************************************\n",
    "\n",
    "# start_frame = int(start_sec * fps)\n",
    "# end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# # Set the video writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Set the current frame number to the start frame\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# # Loop through the frames and write them to the output video\n",
    "# for i in range(start_frame, end_frame):\n",
    "#     ret, frame = video.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Normalize the pixel values to the range [0, 1]\n",
    "#     frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "#     # Apply gamma correction\n",
    "#     frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "#     # Scale the pixel values back to the range [0, 255]\n",
    "#     frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "#     out.write(frame_scaled)\n",
    "\n",
    "# # Release the video objects\n",
    "# video.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392891f-3388-467f-8f53-ac04fc00cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c79ca-9bdb-4e2b-8c2e-867387ae2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.move('CropGr.mp4', 'final_video/CropGr.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fa656-4809-4010-895e-7578d26eb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('final_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32119dff-6ecf-4cb8-b64c-82640c8bf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsv = deeplabcut.DownSampleVideo('CropGr.mp4', width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f08c3-abf8-4f99-915d-50b9c465116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/final_video/CropGr.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386bb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = dsv\n",
    "bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "video_down = file\n",
    "\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490386f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'DLC_GazeXBI'\n",
    "your_name = 'anc'\n",
    "\n",
    "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name,\n",
    "    your_name,\n",
    "    video_down,\n",
    "    videotype=videotype,\n",
    "    model=model_selection,\n",
    "    analyzevideo=True,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ae6bb-1716-4997-a815-30f5978d3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edits = {\n",
    "    'dotsize': 1.5,  # size of the dots!\n",
    "    'pcutoff': 0.4,  # the higher, the more conservative the plotting!\n",
    "}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "project_path = os.path.dirname(config_path)\n",
    "full_video_path = os.path.join(\n",
    "    project_path,\n",
    "    'videos',\n",
    "    os.path.basename(video_down),\n",
    ")\n",
    "\n",
    "# filter predictions (should already be done above ;):\n",
    "deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "# re-create the video with your edits!\n",
    "# deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True,\n",
    "                                filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdf6ca-a6b2-4b43-adc8-38a0091ad2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move('/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4', '/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f6e7-0077-4abc-a815-00912e48cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('/home/yramakrishna/DeepLabCut/conda-environments/final_video')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4314b3-5e42-4de8-b333-ccebc4245872",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Longdownsampled.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e155ed-c842-4f01-ba18-e0d6b38fafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "videoplayer = TkinterVideo(master=root, scaled=True)\n",
    "videoplayer.load(r\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4\")\n",
    "videoplayer.pack(expand=True, fill=\"both\")\n",
    "\n",
    "videoplayer.play() # play the video\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511066-14c1-44d0-9566-9a2975babd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\")\n",
    "# ret, frame = cap.read()\n",
    "# while(1):\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
    "#        cap.release()\n",
    "#        cv2.destroyAllWindows()\n",
    "#        break\n",
    "#    cv2.imshow('frame',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfab5c-99f8-427b-9bb0-634efbe8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# import pygame\n",
    " \n",
    "# clip = VideoFileClip('/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4')\n",
    "# clip.preview()\n",
    " \n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c14e94-b374-4c21-abce-0af196dfb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# from tkvideo import tkvideo\n",
    "\n",
    "# root = Tk()\n",
    "# my_label = Label(root)\n",
    "# my_label.pack()\n",
    "# player = tkvideo(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\", my_label, loop = 1, size = (1280,720))\n",
    "# player.play()\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b47575-5bfd-4a6b-977a-f6e6692e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlc_model = config_path\n",
    "# dlc_config = deeplabcut.load_config(config_file)\n",
    "# dlc_model = deeplabcut.getModel(dlc_config)\n",
    "\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture(video_down)\n",
    "\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropMFace.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "\n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         out.write(frame_scaled)\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "\n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# out.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b60d65-a764-415f-8f9e-037d4941d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import deeplabcut\n",
    "\n",
    "# # Load the DeepLabCut model\n",
    "# config_file = 'path/to/config.yaml'\n",
    "# dlc_model = deeplabcut.load_model(config_file)\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture('path/to/video')\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "    \n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "        \n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "    \n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
