{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a40da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 12:35:54.671461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 12:35:54.777929: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-29 12:35:55.086589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-03-29 12:35:55.086641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-03-29 12:35:55.086646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dda329f-efda-445e-a58c-1a87f8ad2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Long.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeda2adf-dc33-4685-97cb-8aa71535dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "model = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"Ken_Test_Long.mp4\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Set the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "check = False\n",
    "gamma = 2\n",
    "\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Loop through the frames in the video\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    check = False\n",
    "    \n",
    "    # Check if the frame was successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Resize the frame to a smaller size (for faster processing)\n",
    "    small_frame = cv2.resize(frame, (300, 300))\n",
    "    \n",
    "    # Preprocess the frame for input to the neural network\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    # Pass the blob through the neural network to detect faces\n",
    "    model.setInput(blob)\n",
    "    detections = model.forward()\n",
    "    \n",
    "    # Loop through the detections and draw rectangles around the monkey faces\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:  # Only show faces with high confidence+\n",
    "            check = True\n",
    "            # box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            # (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            # cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    \n",
    "    if check:\n",
    "        # cv2.imshow(\"Monkey faces\", frame)\n",
    "        #Normalize the pixel values to the range [0, 1]\n",
    "#         frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "#         # Apply gamma correction\n",
    "#         frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "#         # Scale the pixel values back to the range [0, 255]\n",
    "#         frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "        out.write(frame)\n",
    "    # Show the frame with monkey faces detected\n",
    "    #cv2.imshow(\"Monkey faces\", frame)\n",
    "    \n",
    "    # Wait for a key press\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video file and close the window\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d9b93-8d3f-46ff-afdf-60bbc79461c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cropping video and Gamma correction\n",
    "\n",
    "# # Load the video file\n",
    "# video = cv2.VideoCapture(dsv)\n",
    "\n",
    "# # Get the frame rate and total number of frames\n",
    "# fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# #*********************************************\n",
    "\n",
    "# # Set the start and end points to crop out\n",
    "# start_sec = 10  # Crop out the first x seconds\n",
    "# end_sec = 10 # Crop out the last y seconds\n",
    "\n",
    "# #Set gamma correction value\n",
    "# gamma = 2\n",
    "\n",
    "# #**********************************************\n",
    "\n",
    "# start_frame = int(start_sec * fps)\n",
    "# end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# # Set the video writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Set the current frame number to the start frame\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# # Loop through the frames and write them to the output video\n",
    "# for i in range(start_frame, end_frame):\n",
    "#     ret, frame = video.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Normalize the pixel values to the range [0, 1]\n",
    "#     frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "#     # Apply gamma correction\n",
    "#     frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "#     # Scale the pixel values back to the range [0, 255]\n",
    "#     frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "#     out.write(frame_scaled)\n",
    "\n",
    "# # Release the video objects\n",
    "# video.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f392891f-3388-467f-8f53-ac04fc00cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d2c79ca-9bdb-4e2b-8c2e-867387ae2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_video/CropGr.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move('CropGr.mp4', 'final_video/CropGr.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f6fa656-4809-4010-895e-7578d26eb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('final_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32119dff-6ecf-4cb8-b64c-82640c8bf95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc --enable-libsmbclient\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'CropGr.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:03:01.14, start: 0.000000, bitrate: 3806 kb/s\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 3805 kb/s, 29 fps, 29 tbr, 14848 tbn, 29 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x564f09418ec0] using SAR=4/3\n",
      "[libx264 @ 0x564f09418ec0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x564f09418ec0] profile High, level 1.3, 4:2:0, 8-bit\n",
      "[libx264 @ 0x564f09418ec0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'CropGrdownsampled.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 320x240 [SAR 4:3 DAR 16:9], q=2-31, 29 fps, 14848 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame= 5253 fps=1726 q=-1.0 Lsize=    3026kB time=00:03:01.03 bitrate= 136.9kbits/s speed=59.5x    \n",
      "video:2964kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.098736%\n",
      "[libx264 @ 0x564f09418ec0] frame I:25    Avg QP:21.13  size: 14084\n",
      "[libx264 @ 0x564f09418ec0] frame P:1342  Avg QP:24.10  size:  1712\n",
      "[libx264 @ 0x564f09418ec0] frame B:3886  Avg QP:30.67  size:    99\n",
      "[libx264 @ 0x564f09418ec0] consecutive B-frames:  0.9%  0.9%  1.9% 96.3%\n",
      "[libx264 @ 0x564f09418ec0] mb I  I16..4:  3.4% 50.0% 46.5%\n",
      "[libx264 @ 0x564f09418ec0] mb P  I16..4:  0.4%  3.6%  1.1%  P16..4: 32.2% 16.4%  9.1%  0.0%  0.0%    skip:37.2%\n",
      "[libx264 @ 0x564f09418ec0] mb B  I16..4:  0.0%  0.1%  0.0%  B16..8: 12.4%  0.9%  0.2%  direct: 0.4%  skip:86.0%  L0:46.1% L1:49.6% BI: 4.3%\n",
      "[libx264 @ 0x564f09418ec0] 8x8 transform intra:65.7% inter:65.7%\n",
      "[libx264 @ 0x564f09418ec0] coded y,uvDC,uvAC intra: 88.4% 89.8% 51.8% inter: 8.1% 9.1% 0.6%\n",
      "[libx264 @ 0x564f09418ec0] i16 v,h,dc,p:  4% 52%  3% 41%\n",
      "[libx264 @ 0x564f09418ec0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 17% 10%  8%  8% 11%  7% 13% 10%\n",
      "[libx264 @ 0x564f09418ec0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 40%  8%  5%  5%  8%  5%  7%  5%\n",
      "[libx264 @ 0x564f09418ec0] i8c dc,h,v,p: 43% 30% 16% 11%\n",
      "[libx264 @ 0x564f09418ec0] Weighted P-Frames: Y:3.1% UV:2.0%\n",
      "[libx264 @ 0x564f09418ec0] ref P L0: 63.3% 20.9%  9.8%  5.9%  0.2%\n",
      "[libx264 @ 0x564f09418ec0] ref B L0: 94.0%  3.6%  2.4%\n",
      "[libx264 @ 0x564f09418ec0] ref B L1: 97.8%  2.2%\n",
      "[libx264 @ 0x564f09418ec0] kb/s:134.01\n"
     ]
    }
   ],
   "source": [
    "dsv = deeplabcut.DownSampleVideo('CropGr.mp4', width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756f08c3-abf8-4f99-915d-50b9c465116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/final_video/CropGr.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386bb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = dsv\n",
    "bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "video_down = file\n",
    "\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490386f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/labeled-data\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/training-datasets\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/dlc-models\"\n",
      "1  videos from the directory . were added to the project.\n",
      "Copying the videos\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4\n",
      "Generated \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/config.yaml\"\n",
      "\n",
      "A new project with name DLC_GazeXBI-anc-2023-03-29 is created at /home/yramakrishna/DeepLabCut/conda-environments/final_video and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... primate_face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8fb196cff24bb2b30e3b0656739ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n-1_shuffle-1.tar.gz:   0%|          | 0.00/198M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/dlc-models/iteration-0/DLC_GazeXBIMar29-trainset95shuffle1/train/pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-1030000 for model /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/dlc-models/iteration-0/DLC_GazeXBIMar29-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-03-29 12:41:22.732242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:22.745967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:22.746136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:22.746473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 12:41:22.747675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:22.747825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:22.747972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:23.029769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:23.029929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:23.030050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 12:41:23.030138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13439 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:51:00.0, compute capability: 8.9\n",
      "2023-03-29 12:41:23.046702: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4\n",
      "Duration of video [s]:  181.14 , recorded with  29.0 fps!\n",
      "Overall # of frames:  5253  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/5253 [00:00<?, ?it/s]2023-03-29 12:41:24.259399: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-03-29 12:41:24.634053: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████████████████████████████████| 5253/5253 [00:09<00:00, 581.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    }
   ],
   "source": [
    "project_name = 'DLC_GazeXBI'\n",
    "your_name = 'anc'\n",
    "\n",
    "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name,\n",
    "    your_name,\n",
    "    video_down,\n",
    "    videotype=videotype,\n",
    "    model=model_selection,\n",
    "    analyzevideo=True,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "130ae6bb-1716-4997-a815-30f5978d3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7705e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4\n",
      "Saving filtered csv poses!\n",
      "Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampled.mp4 and data.\n",
      "Duration of video [s]: 181.14, recorded with 29.0 fps!\n",
      "Overall # of frames: 5253 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5253/5253 [00:04<00:00, 1050.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits = {\n",
    "    'dotsize': 1.5,  # size of the dots!\n",
    "    'pcutoff': 0.4,  # the higher, the more conservative the plotting!\n",
    "}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "project_path = os.path.dirname(config_path)\n",
    "full_video_path = os.path.join(\n",
    "    project_path,\n",
    "    'videos',\n",
    "    os.path.basename(video_down),\n",
    ")\n",
    "\n",
    "# filter predictions (should already be done above ;):\n",
    "deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "# re-create the video with your edits!\n",
    "# deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True,\n",
    "                                filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbdf6ca-a6b2-4b43-adc8-38a0091ad2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move('/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-29/videos/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4', '/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c65f6e7-0077-4abc-a815-00912e48cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('/home/yramakrishna/DeepLabCut/conda-environments/final_video')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4314b3-5e42-4de8-b333-ccebc4245872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: /home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Longdownsampled.mp4 - No such file or directory.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Longdownsampled.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0e155ed-c842-4f01-ba18-e0d6b38fafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "videoplayer = TkinterVideo(master=root, scaled=True)\n",
    "videoplayer.load(r\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4\")\n",
    "videoplayer.pack(expand=True, fill=\"both\")\n",
    "\n",
    "videoplayer.play() # play the video\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93511066-14c1-44d0-9566-9a2975babd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\")\n",
    "# ret, frame = cap.read()\n",
    "# while(1):\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
    "#        cap.release()\n",
    "#        cv2.destroyAllWindows()\n",
    "#        break\n",
    "#    cv2.imshow('frame',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64dfab5c-99f8-427b-9bb0-634efbe8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# import pygame\n",
    " \n",
    "# clip = VideoFileClip('/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4')\n",
    "# clip.preview()\n",
    " \n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c14e94-b374-4c21-abce-0af196dfb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# from tkvideo import tkvideo\n",
    "\n",
    "# root = Tk()\n",
    "# my_label = Label(root)\n",
    "# my_label.pack()\n",
    "# player = tkvideo(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\", my_label, loop = 1, size = (1280,720))\n",
    "# player.play()\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b47575-5bfd-4a6b-977a-f6e6692e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlc_model = config_path\n",
    "# dlc_config = deeplabcut.load_config(config_file)\n",
    "# dlc_model = deeplabcut.getModel(dlc_config)\n",
    "\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture(video_down)\n",
    "\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropMFace.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "\n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         out.write(frame_scaled)\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "\n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# out.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b60d65-a764-415f-8f9e-037d4941d7f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (3415417350.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_65589/3415417350.py\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tkVideoPlayer/tkvideoplayer.py\", line 173, in _load\n",
      "    self.event_generate(\"<<FrameGenerated>>\")\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/tkinter/__init__.py\", line 1858, in event_generate\n",
      "    self.tk.call(args)\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import deeplabcut\n",
    "\n",
    "# # Load the DeepLabCut model\n",
    "# config_file = 'path/to/config.yaml'\n",
    "# dlc_model = deeplabcut.load_model(config_file)\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture('path/to/video')\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "    \n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "        \n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "    \n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
