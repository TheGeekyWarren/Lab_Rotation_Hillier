{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b58a4a-8012-4408-a34d-51ae74380142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from deeplabcut.utils import auxiliaryfunctions, visualization\n",
    "\n",
    "# Load the ground truth video and the DeepLabCut model\n",
    "ground_truth_video = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/Codes/FaceNoface.mp4\")\n",
    "\n",
    "\n",
    "# Create a Deeplabcut auxiliary function to load the model\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n",
    "\n",
    "\n",
    "# Define the facial features to compare\n",
    "features_to_compare = [bodyparts = [ 'LeftEye_Outer', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']]\n",
    "\n",
    "# Loop over the video frames\n",
    "mse_sum = 0\n",
    "num_frames = 0\n",
    "while True:\n",
    "    ret, frame = ground_truth_video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract the ground truth features from the frame\n",
    "    ground_truth_features = []\n",
    "    for feature in features_to_compare:\n",
    "        x, y = get_feature_location_from_ground_truth(frame, feature)\n",
    "        ground_truth_features.append([x, y])\n",
    "\n",
    "    # Extract the DeepLabCut features from the frame\n",
    "    dlc_features = []\n",
    "    dlc_keypoints = dlc_model.predict_single_image(frame, cropped=False, detection_thresh=0.1)\n",
    "    for feature in features_to_compare:\n",
    "        x, y, confidence = get_feature_location_from_dlc_keypoints(dlc_keypoints, feature)\n",
    "        if confidence > 0:\n",
    "            dlc_features.append([x, y])\n",
    "        else:\n",
    "            dlc_features.append([np.nan, np.nan])\n",
    "\n",
    "    # Compute the mean squared error between the ground truth and DeepLabCut features\n",
    "    mse = np.mean((np.array(ground_truth_features) - np.array(dlc_features)) ** 2)\n",
    "    mse_sum += mse\n",
    "    num_frames += 1\n",
    "\n",
    "# Compute the average mean squared error over all frames\n",
    "avg_mse = mse_sum / num_frames\n",
    "\n",
    "# Print the result\n",
    "print(\"The average mean squared error between the ground truth and DeepLabCut features is:\", avg_mse)\n",
    "\n",
    "# Release the video capture\n",
    "ground_truth_video.release()\n",
    "\n",
    "# Define functions to extract the feature locations from the ground truth and DeepLabCut keypoints\n",
    "def get_feature_location_from_ground_truth(frame, feature):\n",
    "    # You should implement this function based on how the ground truth features are labelled in the video.\n",
    "\n",
    "def get_feature_location_from_dlc_keypoints(keypoints, feature):\n",
    "    index = dlc_cfg['all_joints_names'].index(feature)\n",
    "    x = keypoints[index][0]\n",
    "    y = keypoints[index][1]\n",
    "    confidence = keypoints[index][2]\n",
    "    return x, y, confidence\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
