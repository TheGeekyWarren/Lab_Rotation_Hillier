{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a40da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 15:55:48.054455: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 15:55:48.161802: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-17 15:55:48.473451: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-04-17 15:55:48.473495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-04-17 15:55:48.473499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b700dcec-1a1d-4fbd-9599-509f89a6f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yramakrishna/DeepLabCut/conda-environments/Codes'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a53b65-3cb3-4546-b1db-c7ae3279c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('dynamic cropping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dda329f-efda-445e-a58c-1a87f8ad2cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/2023-01-13-14-35-40.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5526d67f-7e5e-4b40-b951-18696737e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subprocess.run(['ffmpeg', '-i', start_file, '-c:v', 'libx264', '-preset', 'slow', '-crf', '22', '-c:a', 'copy', 'outputu.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32119dff-6ecf-4cb8-b64c-82640c8bf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsv = deeplabcut.DownSampleVideo(start_file, width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54660f26-d56e-4911-988b-9a9fbbab2b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#start_file2  = '/home/yramakrishna/DeepLabCut/conda-environments/outputu.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5d9b93-8d3f-46ff-afdf-60bbc79461c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping video and Gamma correction\n",
    "\n",
    "# Load the video file\n",
    "video = cv2.VideoCapture(start_file)\n",
    "\n",
    "# Get the frame rate and total number of frames\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#*********************************************\n",
    "\n",
    "# Set the start and end points to crop out\n",
    "start_sec = 0  # Crop out the first x seconds\n",
    "end_sec = 0 # Crop out the last y seconds\n",
    "\n",
    "#Set gamma correction value\n",
    "gamma = 1\n",
    "\n",
    "#**********************************************\n",
    "\n",
    "start_frame = int(start_sec * fps)\n",
    "end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# Set the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('gamma corrected laura1.avi', fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Set the current frame number to the start frame\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Loop through the frames and write them to the output video\n",
    "for i in range(start_frame, end_frame):\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "    # Apply gamma correction\n",
    "    frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "    # Scale the pixel values back to the range [0, 255]\n",
    "    frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "    out.write(frame_scaled)\n",
    "\n",
    "# Release the video objects\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1220ea-fb0a-4403-8007-bde51aa1c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f392891f-3388-467f-8f53-ac04fc00cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2c79ca-9bdb-4e2b-8c2e-867387ae2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_video/gamma corrected laura1.avi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move('gamma corrected laura1.avi', 'final_video/gamma corrected laura1.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6fa656-4809-4010-895e-7578d26eb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('final_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386bb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = 'gamma corrected laura1.avi'\n",
    "bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "video_down = file\n",
    "\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490386f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/labeled-data\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/training-datasets\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/dlc-models\"\n",
      "1  videos from the directory . were added to the project.\n",
      "Copying the videos\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi\n",
      "Generated \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/config.yaml\"\n",
      "\n",
      "A new project with name DLC_GazeXBI-anc-2023-04-17 is created at /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... primate_face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7412ec3eea3e42d999428e2163e773b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n-1_shuffle-1.tar.gz:   0%|          | 0.00/198M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/dlc-models/iteration-0/DLC_GazeXBIApr17-trainset95shuffle1/train/pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-1030000 for model /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/dlc-models/iteration-0/DLC_GazeXBIApr17-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-04-17 15:56:06.402633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.415444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.415612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.416027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 15:56:06.417039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.417180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.417306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.673836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.673996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.674121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-17 15:56:06.674202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13933 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:51:00.0, compute capability: 8.9\n",
      "2023-04-17 15:56:06.690335: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi\n",
      "Duration of video [s]:  2.0 , recorded with  10.0 fps!\n",
      "Overall # of frames:  20  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]2023-04-17 15:56:08.039770: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-04-17 15:56:08.425033: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "project_name = 'DLC_GazeXBI'\n",
    "your_name = 'anc'\n",
    "\n",
    "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name,\n",
    "    your_name,\n",
    "    video_down,\n",
    "    videotype=videotype,\n",
    "    model=model_selection,\n",
    "    analyzevideo=True,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c54982-8615-4924-9e8b-936a0347575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi\n",
      "Saving filtered csv poses!\n",
      "Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/Codes/dynamic cropping/final_video/DLC_GazeXBI-anc-2023-04-17/videos/gamma corrected laura1.avi and data.\n",
      "Duration of video [s]: 2.0, recorded with 10.0 fps!\n",
      "Overall # of frames: 20 with cropped frame dimensions: 1920 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:00<00:00, 74.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits = {\n",
    "    'dotsize': 1.5,  # size of the dots!\n",
    "    'pcutoff': 0.3,  # the higher, the more conservative the plotting!\n",
    "}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "project_path = os.path.dirname(config_path)\n",
    "full_video_path = os.path.join(\n",
    "    project_path,\n",
    "    'videos',\n",
    "    os.path.basename(video_down),\n",
    ")\n",
    "\n",
    "# filter predictions (should already be done above ;):\n",
    "deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "# re-create the video with your edits!\n",
    "# deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True, filtered=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37561598-a3a9-4c1e-a322-83f5b0dcb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_pth = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000.h5'\n",
    "\n",
    "alt_full_video_path = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_labeled.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "130ae6bb-1716-4997-a815-30f5978d3677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67486/3394946798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load tracking results generated by DeepLabCut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtracking_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfl_pth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the names of the facial features that you want to extract frames for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000.h5 does not exist"
     ]
    }
   ],
   "source": [
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))\n",
    "\n",
    "# Load tracking results generated by DeepLabCut\n",
    "tracking_data = pd.read_hdf(fl_pth)\n",
    "\n",
    "# Define the names of the facial features that you want to extract frames for\n",
    "feature_names = ['RightEye_Pupil','LeftEye_Pupil', 'NostrilsTop_Centre', 'OutlineTop_Mid']\n",
    "\n",
    "# Define the threshold for the confidence score of the facial features\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "# Load the input video\n",
    "cap = cv2.VideoCapture(alt_full_video_path)\n",
    "\n",
    "# Define the output video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Crpoutput_video.AVI', fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Loop through the video frames and extract frames with facial features\n",
    "frame_number = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Get the tracking data for the current frame\n",
    "        frame_data = tracking_data.loc[frame_number]\n",
    "\n",
    "        # Check if the desired facial features are present in the frame\n",
    "        feature_present = False\n",
    "        check = 0\n",
    "        for feature_name in feature_names:\n",
    "            if feature_name in frame_data.loc['DLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000'] and frame_data.loc['DLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000'].loc[feature_name].loc['likelihood'] > confidence_threshold:\n",
    "                check += 1\n",
    "        if check==4:\n",
    "            feature_present = True\n",
    "\n",
    "        # If the desired facial features are present, save the frame to the output video\n",
    "        if feature_present: #check==4\n",
    "            cv2.imshow('output', frame)\n",
    "            out.write(frame)\n",
    "\n",
    "        # Display the output\n",
    "        #cv2.imshow('output', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Increment the frame number\n",
    "        frame_number += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fbdf6ca-a6b2-4b43-adc8-38a0091ad2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.move('/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5', '/home/yramakrishna/DeepLabCut/conda-environments/Codes/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420e6d2a-ed1b-47f0-bbaa-0ee49ef319ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/Crpoutput_video.mp4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# final_fl_pth = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5\n",
    "# full_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c65f6e7-0077-4abc-a815-00912e48cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     shutil.rmtree('/home/yramakrishna/DeepLabCut/conda-environments/final_video')\n",
    "# except OSError as e:\n",
    "#     # If it fails, inform the user.\n",
    "#     print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d4314b3-5e42-4de8-b333-ccebc4245872",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/Codes/Ken_Test_Longdownsampled.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e155ed-c842-4f01-ba18-e0d6b38fafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tkVideoPlayer/tkvideoplayer.py\", line 106, in _load\n",
      "    with av.open(path) as self._container:\n",
      "  File \"av/container/core.pyx\", line 401, in av.container.core.open\n",
      "  File \"av/container/core.pyx\", line 272, in av.container.core.Container.__cinit__\n",
      "  File \"av/container/core.pyx\", line 292, in av.container.core.Container.err_check\n",
      "  File \"av/error.pyx\", line 336, in av.error.err_check\n",
      "av.error.FileNotFoundError: [Errno 2] No such file or directory: '/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4'\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "videoplayer = TkinterVideo(master=root, scaled=True)\n",
    "videoplayer.load(final)\n",
    "videoplayer.pack(expand=True, fill=\"both\")\n",
    "\n",
    "videoplayer.play() # play the video\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511066-14c1-44d0-9566-9a2975babd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\")\n",
    "# ret, frame = cap.read()\n",
    "# while(1):\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
    "#        cap.release()\n",
    "#        cv2.destroyAllWindows()\n",
    "#        break\n",
    "#    cv2.imshow('frame',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfab5c-99f8-427b-9bb0-634efbe8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# import pygame\n",
    " \n",
    "# clip = VideoFileClip('/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4')\n",
    "# clip.preview()\n",
    " \n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c14e94-b374-4c21-abce-0af196dfb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# from tkvideo import tkvideo\n",
    "\n",
    "# root = Tk()\n",
    "# my_label = Label(root)\n",
    "# my_label.pack()\n",
    "# player = tkvideo(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\", my_label, loop = 1, size = (1280,720))\n",
    "# player.play()\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b47575-5bfd-4a6b-977a-f6e6692e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlc_model = config_path\n",
    "# dlc_config = deeplabcut.load_config(config_file)\n",
    "# dlc_model = deeplabcut.getModel(dlc_config)\n",
    "\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture(video_down)\n",
    "\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropMFace.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "\n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         out.write(frame_scaled)\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "\n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# out.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b60d65-a764-415f-8f9e-037d4941d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import deeplabcut\n",
    "\n",
    "# # Load the DeepLabCut model\n",
    "# config_file = 'path/to/config.yaml'\n",
    "# dlc_model = deeplabcut.load_model(config_file)\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture('path/to/video')\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "    \n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "        \n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "    \n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
