{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a40da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 17:27:21.139476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 17:27:21.242186: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-31 17:27:21.563372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-03-31 17:27:21.563418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-03-31 17:27:21.563423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dda329f-efda-445e-a58c-1a87f8ad2cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/iggJos_20211220_092035_00049.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5526d67f-7e5e-4b40-b951-18696737e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, avi, from '/home/yramakrishna/DeepLabCut/conda-environments/iggJos_20211220_092035_00049.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf59.27.100\n",
      "  Duration: 00:00:01.00, start: 0.000000, bitrate: 485 kb/s\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (XVID / 0x44495658), yuv420p, 1280x960 [SAR 1:1 DAR 4:3], 1 fps, 1 tbr, 1 tbn, 1 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x55df3cf40a40] using SAR=1/1\n",
      "[libx264 @ 0x55df3cf40a40] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x55df3cf40a40] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x55df3cf40a40] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=30 lookahead_threads=5 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=1 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=22.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'outputu.mp4':\n",
      "  Metadata:\n",
      "    software        : Lavf59.27.100\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1280x960 [SAR 1:1 DAR 4:3], q=2-31, 1 fps, 16384 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=    1 fps=0.0 q=16.0 Lsize=      80kB time=00:00:00.00 bitrate=10795147.5kbits/s speed=0.000535x    \n",
      "video:80kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.032256%\n",
      "[libx264 @ 0x55df3cf40a40] frame I:1     Avg QP:14.08  size: 80783\n",
      "[libx264 @ 0x55df3cf40a40] mb I  I16..4: 20.7% 76.5%  2.8%\n",
      "[libx264 @ 0x55df3cf40a40] 8x8 transform intra:76.5%\n",
      "[libx264 @ 0x55df3cf40a40] coded y,uvDC,uvAC intra: 70.0% 87.7% 35.9%\n",
      "[libx264 @ 0x55df3cf40a40] i16 v,h,dc,p: 49% 26% 23%  1%\n",
      "[libx264 @ 0x55df3cf40a40] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 24% 42%  2%  1%  2%  1%  2%  3%\n",
      "[libx264 @ 0x55df3cf40a40] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 46% 43%  7%  1%  1%  1%  1%  1%  1%\n",
      "[libx264 @ 0x55df3cf40a40] i8c dc,h,v,p: 16% 42% 37%  6%\n",
      "[libx264 @ 0x55df3cf40a40] kb/s:646.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', '/home/yramakrishna/DeepLabCut/conda-environments/iggJos_20211220_092035_00049.avi', '-c:v', 'libx264', '-preset', 'slow', '-crf', '22', '-c:a', 'copy', 'outputu.mp4'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['ffmpeg', '-i', start_file, '-c:v', 'libx264', '-preset', 'slow', '-crf', '22', '-c:a', 'copy', 'outputu.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32119dff-6ecf-4cb8-b64c-82640c8bf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsv = deeplabcut.DownSampleVideo(start_file, width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54660f26-d56e-4911-988b-9a9fbbab2b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_file2  = '/home/yramakrishna/DeepLabCut/conda-environments/outputu.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5d9b93-8d3f-46ff-afdf-60bbc79461c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping video and Gamma correction\n",
    "\n",
    "# Load the video file\n",
    "video = cv2.VideoCapture(start_file2)\n",
    "\n",
    "# Get the frame rate and total number of frames\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#*********************************************\n",
    "\n",
    "# Set the start and end points to crop out\n",
    "start_sec = 0  # Crop out the first x seconds\n",
    "end_sec = 0 # Crop out the last y seconds\n",
    "\n",
    "#Set gamma correction value\n",
    "gamma = 3\n",
    "\n",
    "#**********************************************\n",
    "\n",
    "start_frame = int(start_sec * fps)\n",
    "end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# Set the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Set the current frame number to the start frame\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Loop through the frames and write them to the output video\n",
    "for i in range(start_frame, end_frame):\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "    # Apply gamma correction\n",
    "    frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "    # Scale the pixel values back to the range [0, 255]\n",
    "    frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "    out.write(frame_scaled)\n",
    "\n",
    "# Release the video objects\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1220ea-fb0a-4403-8007-bde51aa1c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f392891f-3388-467f-8f53-ac04fc00cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2c79ca-9bdb-4e2b-8c2e-867387ae2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_video/CropGr.mp4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move('CropGr.mp4', 'final_video/CropGr.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f6fa656-4809-4010-895e-7578d26eb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('final_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386bb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file = 'CropGr.mp4'\n",
    "bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "video_down = file\n",
    "\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490386f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/labeled-data\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/training-datasets\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/dlc-models\"\n",
      "1  videos from the directory . were added to the project.\n",
      "Copying the videos\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4\n",
      "Generated \"/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/config.yaml\"\n",
      "\n",
      "A new project with name DLC_GazeXBI-anc-2023-03-31 is created at /home/yramakrishna/DeepLabCut/conda-environments/final_video and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... primate_face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59602a4d8ace4795af90407edc57a770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n-1_shuffle-1.tar.gz:   0%|          | 0.00/198M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/dlc-models/iteration-0/DLC_GazeXBIMar31-trainset95shuffle1/train/pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-1030000 for model /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/dlc-models/iteration-0/DLC_GazeXBIMar31-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-03-31 17:27:31.923856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:31.937331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:31.937502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:31.937830: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 17:27:31.939203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:31.939348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:31.939475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:32.214149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:32.214307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:32.214441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-31 17:27:32.214522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13228 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:51:00.0, compute capability: 8.9\n",
      "2023-03-31 17:27:32.231608: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4\n",
      "Duration of video [s]:  1.0 , recorded with  1.0 fps!\n",
      "Overall # of frames:  1  found with (before cropping) frame dimensions:  1280 960\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2023-03-31 17:27:33.533437: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-03-31 17:27:33.912510: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "project_name = 'DLC_GazeXBI'\n",
    "your_name = 'anc'\n",
    "\n",
    "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name,\n",
    "    your_name,\n",
    "    video_down,\n",
    "    videotype=videotype,\n",
    "    model=model_selection,\n",
    "    analyzevideo=True,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c54982-8615-4924-9e8b-936a0347575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/scipy/signal/_signaltools.py:1545: UserWarning: kernel_size exceeds volume extent: the volume will be zero-padded.\n",
      "  warnings.warn('kernel_size exceeds volume extent: the volume will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-31/videos/CropGr.mp4 and data.\n",
      "Duration of video [s]: 1.0, recorded with 1.0 fps!\n",
      "Overall # of frames: 1 with cropped frame dimensions: 1280 960\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 81.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits = {\n",
    "    'dotsize': 1.5,  # size of the dots!\n",
    "    'pcutoff': 0.3,  # the higher, the more conservative the plotting!\n",
    "}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "project_path = os.path.dirname(config_path)\n",
    "full_video_path = os.path.join(\n",
    "    project_path,\n",
    "    'videos',\n",
    "    os.path.basename(video_down),\n",
    ")\n",
    "\n",
    "# filter predictions (should already be done above ;):\n",
    "deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "# re-create the video with your edits!\n",
    "# deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37561598-a3a9-4c1e-a322-83f5b0dcb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_pth = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5'\n",
    "\n",
    "alt_full_video_path = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered_labeled.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130ae6bb-1716-4997-a815-30f5978d3677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24560/44298000.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load tracking results generated by DeepLabCut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtracking_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfl_pth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the names of the facial features that you want to extract frames for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5 does not exist"
     ]
    }
   ],
   "source": [
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))\n",
    "\n",
    "# Load tracking results generated by DeepLabCut\n",
    "tracking_data = pd.read_hdf(fl_pth)\n",
    "\n",
    "# Define the names of the facial features that you want to extract frames for\n",
    "feature_names = ['RightEye_Pupil','LeftEye_Pupil', 'NostrilsTop_Centre', 'OutlineTop_Mid']\n",
    "\n",
    "# Define the threshold for the confidence score of the facial features\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "# Load the input video\n",
    "cap = cv2.VideoCapture(alt_full_video_path)\n",
    "\n",
    "# Define the output video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4')\n",
    "out = cv2.VideoWriter('Crpoutput_video.mp4', fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# Loop through the video frames and extract frames with facial features\n",
    "frame_number = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Get the tracking data for the current frame\n",
    "        frame_data = tracking_data.loc[frame_number]\n",
    "\n",
    "        # Check if the desired facial features are present in the frame\n",
    "        feature_present = False\n",
    "        check = 0\n",
    "        for feature_name in feature_names:\n",
    "            if feature_name in frame_data.loc['DLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000'] and frame_data.loc['DLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000'].loc[feature_name].loc['likelihood'] > confidence_threshold:\n",
    "                check += 1\n",
    "        if check==4:\n",
    "            feature_present = True\n",
    "\n",
    "        # If the desired facial features are present, save the frame to the output video\n",
    "        if feature_present: #check==4\n",
    "            cv2.imshow('output', frame)\n",
    "            out.write(frame)\n",
    "\n",
    "        # Display the output\n",
    "        #cv2.imshow('output', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Increment the frame number\n",
    "        frame_number += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fbdf6ca-a6b2-4b43-adc8-38a0091ad2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yramakrishna/DeepLabCut/conda-environments/Codes/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shutil.move('/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5', '/home/yramakrishna/DeepLabCut/conda-environments/Codes/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420e6d2a-ed1b-47f0-bbaa-0ee49ef319ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-03-30/videos/Crpoutput_video.mp4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# final_fl_pth = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/CropGrDLC_resnet50_DLC_GazeXBIMar30shuffle1_1030000_filtered.h5\n",
    "# full_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c65f6e7-0077-4abc-a815-00912e48cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     shutil.rmtree('/home/yramakrishna/DeepLabCut/conda-environments/final_video')\n",
    "# except OSError as e:\n",
    "#     # If it fails, inform the user.\n",
    "#     print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d4314b3-5e42-4de8-b333-ccebc4245872",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/Codes/Ken_Test_Longdownsampled.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e155ed-c842-4f01-ba18-e0d6b38fafee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tkVideoPlayer/tkvideoplayer.py\", line 106, in _load\n",
      "    with av.open(path) as self._container:\n",
      "  File \"av/container/core.pyx\", line 401, in av.container.core.open\n",
      "  File \"av/container/core.pyx\", line 272, in av.container.core.Container.__cinit__\n",
      "  File \"av/container/core.pyx\", line 292, in av.container.core.Container.err_check\n",
      "  File \"av/error.pyx\", line 336, in av.error.err_check\n",
      "av.error.FileNotFoundError: [Errno 2] No such file or directory: '/home/yramakrishna/DeepLabCut/conda-environments/CropGrdownsampledDLC_resnet50_DLC_GazeXBIMar29shuffle1_1030000_filtered_labeled.mp4'\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "videoplayer = TkinterVideo(master=root, scaled=True)\n",
    "videoplayer.load(final)\n",
    "videoplayer.pack(expand=True, fill=\"both\")\n",
    "\n",
    "videoplayer.play() # play the video\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511066-14c1-44d0-9566-9a2975babd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\")\n",
    "# ret, frame = cap.read()\n",
    "# while(1):\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
    "#        cap.release()\n",
    "#        cv2.destroyAllWindows()\n",
    "#        break\n",
    "#    cv2.imshow('frame',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfab5c-99f8-427b-9bb0-634efbe8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# import pygame\n",
    " \n",
    "# clip = VideoFileClip('/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4')\n",
    "# clip.preview()\n",
    " \n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c14e94-b374-4c21-abce-0af196dfb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# from tkvideo import tkvideo\n",
    "\n",
    "# root = Tk()\n",
    "# my_label = Label(root)\n",
    "# my_label.pack()\n",
    "# player = tkvideo(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\", my_label, loop = 1, size = (1280,720))\n",
    "# player.play()\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b47575-5bfd-4a6b-977a-f6e6692e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlc_model = config_path\n",
    "# dlc_config = deeplabcut.load_config(config_file)\n",
    "# dlc_model = deeplabcut.getModel(dlc_config)\n",
    "\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture(video_down)\n",
    "\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropMFace.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "\n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         out.write(frame_scaled)\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "\n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# out.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b60d65-a764-415f-8f9e-037d4941d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import deeplabcut\n",
    "\n",
    "# # Load the DeepLabCut model\n",
    "# config_file = 'path/to/config.yaml'\n",
    "# dlc_model = deeplabcut.load_model(config_file)\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture('path/to/video')\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "    \n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "        \n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "    \n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
