{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28204de-5e8e-4b9e-9219-9d00aa611ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdebeaa-a477-4656-8d02-5939afc6f344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def crop_it(feed):\n",
    "feed = ['/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video5/DLC_GazeXBI-anc-2023-05-02/videos/croppedDLC_resnet50_DLC_GazeXBIMay2shuffle1_1030000_filtered.h5',\n",
    "        '/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video5/DLC_GazeXBI-anc-2023-05-02/videos/croppedDLC_resnet50_DLC_GazeXBIMay2shuffle1_1030000_filtered_labeled.mp4',\n",
    "        'DLC_resnet50_DLC_GazeXBIMay2shuffle1_1030000']\n",
    "fl_pth, vid_pth, x = feed\n",
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))\n",
    "print(\"Starting Cropping\")\n",
    "\n",
    "# Define the names of the facial features that you want to extract frames for\n",
    "feature_names = ['RightEye_Pupil','LeftEye_Pupil', 'NostrilsTop_Centre', 'OutlineTop_Mid']\n",
    "\n",
    "# Load tracking results generated by DeepLabCut\n",
    "tracking_data = pd.read_hdf(fl_pth)\n",
    "# x = tracking_data['DLC_resnet50_DLCApr12shuffle1_1030000'][feature_names]\n",
    "# x.isna().any()\n",
    "\n",
    "necessary_points = tracking_data['DLC_resnet50_DLC_GazeXBIMay2shuffle1_1030000'][feature_names]\n",
    "# Define the threshold for the confidence score of the facial features\n",
    "confidence_threshold = 0.8\n",
    "\n",
    "# Load the input video\n",
    "cap = cv2.VideoCapture(vid_pth)\n",
    " \n",
    "tot_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# initializing the frame id list\n",
    "labels = []\n",
    "tot_yes = 0\n",
    "frame_id=[]\n",
    "\n",
    "# Loop through the video frames and extract frames with facial features\n",
    "frame_number = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # Get the tracking data for the current frame\n",
    "        frame_data = necessary_points.loc[frame_number]\n",
    "        # print(frame_data)\n",
    "\n",
    "        # Check if the desired facial features are present in the frame\n",
    "        feature_present = False\n",
    "        check = 0            \n",
    "        for feature_name in feature_names:\n",
    "            if feature_name in frame_data and frame_data.loc[feature_name].loc['likelihood'] > confidence_threshold:\n",
    "                check += 1\n",
    "        if check==4:\n",
    "            feature_present = True\n",
    "\n",
    "        # If the desired facial features are present, save the frame to the output video\n",
    "        if feature_present: #check==4\n",
    "            tot_yes += 1\n",
    "            labels.append([frame_number, 1])\n",
    "            frame_id.append(frame_number)\n",
    "        else:\n",
    "            labels.append([frame_number, 0])\n",
    "\n",
    "        # Display the output\n",
    "        cv2.imshow('output', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        print(round(frame_number/tot_frame*100, 2), end = '\\r')\n",
    "        # Increment the frame number\n",
    "        frame_number += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "labels.append([tot_yes, (frame_number-tot_yes)])##this list contains the total number of frames with faces (tot_yes) and the total number of frames without faces (frame_index-tot_yes). \n",
    "labels.append([frame_id,0])\n",
    "text_file = open(\"text_fileFacehuman_DLCds.csv\", \"w\")#opens a new file called \"text_fileFacehumands.csv\" in write mode (`\"w\"`). This file will be used to store the face detection information.\n",
    "labelled = pd.DataFrame(labels, columns = ['Frame_id','Face?'])#creates a new Pandas DataFrame called `labelled` from the `labels` list. The DataFrame has two columns named \"Frame_id\" and \"Face\" that correspond to the two values stored in each list within the `labels` list.\n",
    "\n",
    "labelled.to_csv(\"text_fileFacehuman_DLCds.csv\")#saves the `labelled` DataFrame as a CSV file with the filename \"text_fileFacehumands.csv\"\n",
    "\n",
    "print(\"Done\")\n",
    "# Release resources\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()\n",
    "#return frame_ids   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a80c12-0fe2-4e6b-8362-c9d11392de95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
