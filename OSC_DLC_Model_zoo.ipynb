{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302f30c0-0ccc-4e5e-b5de-81aa00c5dcca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 11:32:24.336709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 11:32:24.602394: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-03 11:32:25.132902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-05-03 11:32:25.132960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-05-03 11:32:25.132965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.3...\n",
      "/home/yramakrishna/DeepLabCut/conda-environments\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/labeled-data\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/training-datasets\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/dlc-models\"\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/nil_20210614_XBI19downsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Created the symlink of /home/yramakrishna/DeepLabCut/conda-environments/All_vids/GC_Conv_vids/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 to /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Generated \"/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/config.yaml\"\n",
      "\n",
      "A new project with name DLC-VK-2023-05-03 is created at /home/yramakrishna/DeepLabCut/conda-environments/All_vids and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... primate_face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666ef3dcfc0a4f0392fe6bdd6cbbf2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n-1_shuffle-1.tar.gz:   0%|          | 0.00/198M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/dlc-models/iteration-0/DLCMay3-trainset95shuffle1/train/pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-1030000 for model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/dlc-models/iteration-0/DLCMay3-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-05-03 11:32:37.366266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.452342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.452533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.453064: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 11:32:37.454603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.454759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.454887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.956639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.956799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.956919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-03 11:32:37.957000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13734 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:51:00.0, compute capability: 8.9\n",
      "2023-05-03 11:32:37.974752: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  7791.6 , recorded with  30.0 fps!\n",
      "Overall # of frames:  233748  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/233748 [00:00<?, ?it/s]2023-05-03 11:32:39.607548: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2023-05-03 11:32:40.448000: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████████████████████████████| 233748/233748 [05:09<00:00, 756.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  8507.27 , recorded with  15.0 fps!\n",
      "Overall # of frames:  127609  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 127609/127609 [02:51<00:00, 745.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  5035.56 , recorded with  16.0 fps!\n",
      "Overall # of frames:  80569  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 80569/80569 [01:48<00:00, 740.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4\n",
      "Duration of video [s]:  17931.22 , recorded with  18.0 fps!\n",
      "Overall # of frames:  322762  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 322762/322762 [06:55<00:00, 777.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  7849.97 , recorded with  29.0 fps!\n",
      "Overall # of frames:  227649  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 227649/227649 [05:06<00:00, 742.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  7250.33 , recorded with  9.0 fps!\n",
      "Overall # of frames:  65253  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 65253/65253 [01:29<00:00, 730.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  4089.33 , recorded with  9.0 fps!\n",
      "Overall # of frames:  36804  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 36804/36804 [00:45<00:00, 804.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4\n",
      "Duration of video [s]:  16128.03 , recorded with  30.0 fps!\n",
      "Overall # of frames:  483841  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 483841/483841 [10:49<00:00, 744.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4\n",
      "Duration of video [s]:  3873.3 , recorded with  60.0 fps!\n",
      "Overall # of frames:  232398  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 232398/232398 [05:00<00:00, 772.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  11445.8 , recorded with  15.0 fps!\n",
      "Overall # of frames:  171687  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 171687/171687 [03:45<00:00, 762.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Duration of video [s]:  4590.67 , recorded with  9.0 fps!\n",
      "Overall # of frames:  41316  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 41316/41316 [01:03<00:00, 649.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "Saving filtered csv poses!\n",
      "Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4\n",
      "\n",
      "\n",
      "\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/nil_20210614_XBI19downsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/vin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GC.mp4 and data.\n",
      "\n",
      "\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/All_vids/DLC-VK-2023-05-03/videos/ken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GC.mp4 and data.\n",
      "\n",
      "\n",
      "\n",
      "Duration of video [s]: 4089.33, recorded with 9.0 fps!\n",
      "Overall # of frames: 36804 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/36804 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 4590.67, recorded with 9.0 fps!\n",
      "Overall # of frames: 41316 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/41316 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 7250.33, recorded with 9.0 fps!\n",
      "Overall # of frames: 65253 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n",
      "Duration of video [s]: 5035.56, recorded with 16.0 fps!\n",
      "Overall # of frames: 80569 with cropped frame dimensions: 320 240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/65253 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 241/80569 [00:00<00:33, 2395.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 8507.27, recorded with 15.0 fps!\n",
      "Overall # of frames: 127609 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n",
      "Duration of video [s]: 11445.8, recorded with 15.0 fps!\n",
      "Overall # of frames: 171687 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                      | 130/41316 [00:00<01:07, 614.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 3873.3, recorded with 60.0 fps!\n",
      "Overall # of frames: 232398 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                    | 460/65253 [00:00<00:36, 1774.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 7791.6, recorded with 30.0 fps!\n",
      "Overall # of frames: 233748 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                    | 540/36804 [00:00<00:21, 1721.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 7849.97, recorded with 29.0 fps!\n",
      "Overall # of frames: 227649 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                    | 664/65253 [00:00<00:34, 1877.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 17931.22, recorded with 18.0 fps!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 270/233748 [00:00<01:26, 2699.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall # of frames: 322762 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                    | 773/80569 [00:00<00:41, 1911.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]: 16128.03, recorded with 30.0 fps!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 409/127609 [00:00<01:29, 1424.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall # of frames: 483841 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 36804/36804 [00:12<00:00, 2893.78it/s]\n",
      "100%|███████████████████████████████████| 41316/41316 [00:23<00:00, 1730.26it/s]\n",
      "100%|███████████████████████████████████| 65253/65253 [00:24<00:00, 2708.75it/s]\n",
      "100%|███████████████████████████████████| 80569/80569 [00:34<00:00, 2368.90it/s]\n",
      "100%|█████████████████████████████████| 127609/127609 [00:40<00:00, 3130.95it/s]\n",
      "100%|█████████████████████████████████| 232398/232398 [00:56<00:00, 4131.80it/s]\n",
      "100%|█████████████████████████████████| 171687/171687 [01:05<00:00, 2634.78it/s]\n",
      "100%|█████████████████████████████████| 227649/227649 [01:14<00:00, 3068.93it/s]\n",
      "100%|█████████████████████████████████| 233748/233748 [01:29<00:00, 2624.96it/s]\n",
      "100%|█████████████████████████████████| 322762/322762 [01:30<00:00, 3576.44it/s]\n",
      "100%|█████████████████████████████████| 483841/483841 [02:44<00:00, 2935.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videoken_20210507_1032_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videoken_20210504_1236_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videoken_20210503_0911_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videoken_20210505_0939_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videovin_20210525_0844_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videovin_20210528_1002_XBI19_reversal_learning_foraging_SC3_DCS_frontCameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videoken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videovin_20210604_0907_XBI19_reversal_learning_foraging_SC3_DCS_front_cameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videovin_20210526_1022_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videovin_20210527_1010_XBI19_reversal_learning_foraging_SC3_DCS_frontcameradownsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n",
      "Starting Cropping\n",
      "Output file written -  Crpoutput_videonil_20210614_XBI19downsampled_GCDLC_resnet50_DLCMay3shuffle1_1030000_filtered_labeled.mp4\n",
      "Done0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "# Converting .mov videos to .mp4\n",
    "def conv_mp4(input_file):\n",
    "    out_name = os.path.splitext(input_file)[0].lstrip('.') \n",
    "    print(out_name)\n",
    "    output_file = out_name + '.mp4'\n",
    "\n",
    "    # Run FFmpeg command to convert MOV to MP4\n",
    "    command = f\"ffmpeg -i {input_file} -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k {output_file}\"\n",
    "    subprocess.call(command, shell=True)\n",
    "    new = os.path.join(os.path.dirname(os.path.dirname(output_file)), 'Conv_vids', os.path.basename(output_file))\n",
    "    shutil.move(output_file, new)\n",
    "\n",
    "\n",
    "def downsize(path, to_path):\n",
    "    dsv = deeplabcut.DownSampleVideo(path, width=320, height=240)\n",
    "    shutil.move(dsv, os.path.join(to_path, os.path.basename(dsv)))\n",
    "\n",
    "#cropping video and Gamma correction\n",
    "def gamma_correct(convid):\n",
    "    \n",
    "    # Load the video file\n",
    "    video = cv2.VideoCapture(convid)\n",
    "\n",
    "    # Get the frame rate and total number of frames\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    #*********************************************\n",
    "    # Set appropriate values for target average illumination of the frame\n",
    "    target_br = 0.6\n",
    "\n",
    "    #**********************************************\n",
    "    \n",
    "    target_g = math.log(target_br)\n",
    "    \n",
    "    # Set the video writer\n",
    "    output_name = os.path.splitext(os.path.basename(convid))[0].lstrip('.') + '_AGC.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    start_frame = 0\n",
    "    \n",
    "    # Set the current frame number to the start frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    frame_number = start_frame\n",
    "    \n",
    "    # Loop through the frames and write them to the output video\n",
    "    for i in range(start_frame, total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Normalize the pixel values to the range [0, 1]\n",
    "        frame_normalized = frame.astype(np.float32) / 255.0\n",
    "        gray = cv2.cvtColor(frame_normalized, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Finding the mean luminance of the frame\n",
    "        brightness = np.mean(frame_normalized)\n",
    "\n",
    "        #finding and correcting gamma - a number is assigned to be the 'innate' gamma value of the frame, and that value is used to find the correction needed. \n",
    "        if brightness == 0:\n",
    "            print('err')\n",
    "            continue\n",
    "        assigned_g = math.log(brightness)\n",
    "        gamma = assigned_g/target_g\n",
    "\n",
    "        # Apply gamma correction\n",
    "        frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "        # Scale the pixel values back to the range [0, 255]\n",
    "        frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "        \n",
    "        print(round(frame_number/total_frames*100, 2), end = '\\r')\n",
    "        frame_number += 1\n",
    "        # cv2.imshow('output', frame)\n",
    "        # cv2.imshow('output', frame_scaled)\n",
    "        out.write(frame_scaled)\n",
    "    # new = os.path.join(os.path.dirname(os.path.dirname(convid)), 'GC_Conv_vids', os.path.basename(convid))\n",
    "    # shutil.move(dsv, new)\n",
    "    print(\"Done - \", convid)\n",
    "    print('')\n",
    "    # Release the video objects\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#Processing videos using DeepLabCut ModelZoo's pretrained model - Primate face\n",
    "def process(fold, project_name, your_name):\n",
    "    file = fold[0]\n",
    "    print(file)\n",
    "    bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "                 'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "    videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "    video_down = folder\n",
    "    name_fold = 'Analyse_' + os.path.basename(os.path.dirname(file))\n",
    "    \n",
    "    model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "    model_selection = 'primate_face'\n",
    "\n",
    "    config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "        project_name,\n",
    "        your_name,\n",
    "        video_down,\n",
    "        videotype=videotype,\n",
    "        model=model_selection,\n",
    "        analyzevideo=True,\n",
    "        createlabeledvideo=False,\n",
    "        copy_videos=False,\n",
    "    )\n",
    "\n",
    "    edits = {\n",
    "        'dotsize': 1.5,  # size of the dots!--------------------------------------------------------------------------------------------------------------------------------\n",
    "        'pcutoff': 0.4,  # the higher, the more conservative the plotting!\n",
    "    }\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "    project_path = os.path.dirname(config_path)\n",
    "    full_video_path = []\n",
    "    for i in fold:\n",
    "        full_video_path.append(os.path.join(project_path,'videos', os.path.basename(i)))\n",
    "\n",
    "    # filter predictions (should already be done above ;):\n",
    "    deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "    # re-create the video with your edits!\n",
    "    # deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "    deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True, filtered=True)\n",
    "\n",
    "#Cropping the video based on confidence of facial features\n",
    "def crop_it(feed):\n",
    "    \n",
    "    fl_pth, vid_pth, x = feed\n",
    "    # deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))\n",
    "    print(\"Starting Cropping\")\n",
    "\n",
    "    # Load tracking results generated by DeepLabCut\n",
    "    tracking_data = pd.read_hdf(fl_pth)\n",
    "\n",
    "    # Define the names of the facial features that you want to extract frames for\n",
    "    feature_names = ['RightEye_Pupil','LeftEye_Pupil', 'NostrilsTop_Centre', 'OutlineTop_Mid']\n",
    "\n",
    "    # Define the threshold for the confidence score of the facial features\n",
    "    confidence_threshold = 0.9\n",
    "    \n",
    "    # Load the input video\n",
    "    cap = cv2.VideoCapture(vid_pth)\n",
    "    \n",
    "    tot_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Define the output video writer\n",
    "    bn = os.path.basename(vid_pth).split('.')[0]\n",
    "    out_file = 'Crpoutput_video' + bn + '.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    print(\"Output file written - \", out_file)\n",
    "\n",
    "    # Loop through the video frames and extract frames with facial features\n",
    "    frame_number = 0\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            # Get the tracking data for the current frame\n",
    "            frame_data = tracking_data.loc[frame_number]\n",
    "\n",
    "            # Check if the desired facial features are present in the frame\n",
    "            feature_present = False\n",
    "            check = 0\n",
    "            for feature_name in feature_names:\n",
    "                if feature_name in frame_data.loc[x] and frame_data.loc[x].loc[feature_name].loc['likelihood'] > confidence_threshold:\n",
    "                    check += 1\n",
    "            if check==4:\n",
    "                feature_present = True\n",
    "\n",
    "            # If the desired facial features are present, save the frame to the output video\n",
    "            if feature_present: #check==4\n",
    "                # cv2.imshow('output', frame)\n",
    "                out.write(frame)\n",
    "            # Display the output\n",
    "            #cv2.imshow('output', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            print(round(frame_number/tot_frame*100, 2), end = '\\r')\n",
    "            # Increment the frame number\n",
    "            frame_number += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done\")\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#enter path of folder (including folder name) containing all your videos of interest------------------------------------------------------------------------------------------\n",
    "vid_dir = '/home/yramakrishna/DeepLabCut/conda-environments/Videos'\n",
    "#initializing project name and author's name ---------------------------------------------------------------------------------------------------------------------------------\n",
    "project_name = 'DLC'\n",
    "your_name = 'VK'\n",
    "\n",
    "os.chdir(os.path.dirname(vid_dir))\n",
    "print(os.getcwd())\n",
    "\n",
    "#Create a new folder called All_vids in the current directory\n",
    "if not os.path.exists('All_vids'):\n",
    "        os.makedirs('All_vids')\n",
    "os.chdir('All_vids')\n",
    "\n",
    "to_dir = os.path.join(os.getcwd(), os.path.basename(vid_dir)) #moving the folderwith videos to the current directory\n",
    "shutil.move(vid_dir, to_dir)\n",
    "\n",
    "#Storing converted videos in a new folder\n",
    "if not os.path.exists('Conv_vids'):\n",
    "        os.makedirs('Conv_vids')\n",
    "        \n",
    "\n",
    "#Converting files from mov to MP4 (if any)\n",
    "for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Videos')):\n",
    "    path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Videos', file))\n",
    "    if file.endswith(\".mov\"):\n",
    "        conv_mp4(path)\n",
    "    elif file.endswith(\".mp4\"):\n",
    "        path2=os.path.join(os.path.join(os.path.dirname(to_dir), 'Conv_vids', file))\n",
    "        shutil.copy(path, path2)\n",
    "\n",
    "os.chdir(os.path.dirname(to_dir))\n",
    "\n",
    "if not os.path.exists('Downsize_Conv_vids'):\n",
    "        os.makedirs('Downsize_Conv_vids')\n",
    "os.chdir('Downsize_Conv_vids')\n",
    "\n",
    "# vid_names = []\n",
    "for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Conv_vids')):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Conv_vids', file))\n",
    "        downsize(path, os.getcwd())\n",
    "\n",
    "os.chdir(os.path.dirname(to_dir))\n",
    "\n",
    "#Creae a folder for gamma corrected videos\n",
    "if not os.path.exists('AGC_Conv_vids'):\n",
    "        os.makedirs('AGC_Conv_vids')\n",
    "os.chdir('AGC_Conv_vids')\n",
    "\n",
    "#Applying gamma correction on the mp4 videos\n",
    "for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Downsize_Conv_vids')):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Downsize_Conv_vids', file))\n",
    "        gamma_correct(path)\n",
    "        \n",
    "os.chdir('..')\n",
    "\n",
    "#Compiling a list ofpaths for analysis\n",
    "folder = [] \n",
    "for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'AGC_Conv_vids')):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        path=os.path.join(os.path.join(os.path.dirname(to_dir), 'AGC_Conv_vids', file))\n",
    "        folder.append(path)\n",
    "\n",
    "\n",
    "\n",
    "#Analyzing all videos with ModelZoo\n",
    "process(folder, project_name, your_name)\n",
    "\n",
    "#Collecting files with information on labels, as well as the labelled videos.\n",
    "os.chdir(os.path.join(os.getcwd()))\n",
    "h5files = []\n",
    "vid_to_crop = []\n",
    "today = str(date.today())\n",
    "# today = \"2023-04-12\" -------------------------------------------------Modify if you created the modelzoo files on a different day than today.\n",
    "proj_fold = project_name+'-'+your_name+'-'+today\n",
    "target = os.path.join(os.getcwd(),proj_fold,'videos')\n",
    "for file in os.listdir(target):\n",
    "    if file.endswith(\"filtered.h5\"):\n",
    "        h5files.append(os.path.join(target,file))\n",
    "for file in os.listdir(target):   \n",
    "    if file.endswith(\"labeled.mp4\"):\n",
    "        vid_to_crop.append(os.path.join(target,file))\n",
    "\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd()))\n",
    "if not os.path.exists('Cropped_vids'):\n",
    "        os.makedirs('Cropped_vids')\n",
    "os.chdir('Cropped_vids')\n",
    "\n",
    "crop_source = []\n",
    "\n",
    "if len(h5files)==len(vid_to_crop):\n",
    "    for i in h5files:\n",
    "        found = ''\n",
    "        for j in vid_to_crop:\n",
    "            x = os.path.splitext(i)[0].rstrip('_filtered.h5')\n",
    "            y = os.path.splitext(j)[0].rstrip('filtered_labeled.mp4')\n",
    "            if x==y:\n",
    "                found = j\n",
    "        k = os.path.basename(i)\n",
    "        l = 'DLC' + k.split('DLC')[1] + 'DLC' + k.split('DLC')[2].rstrip('_filtered.h5')\n",
    "        crop_source.append([i,found, l])\n",
    "\n",
    "c_s = np.array(crop_source)\n",
    "\n",
    "all_frames = []\n",
    "\n",
    "for i in c_s:\n",
    "    x = crop_it(i)\n",
    "    all_frames.append([i[1],x])\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d60ac7-8b31-4183-98a4-9c69f53d4f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
