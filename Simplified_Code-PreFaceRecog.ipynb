{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a40da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 11:29:03.629556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 11:29:03.733257: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-20 11:29:04.045084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-04-20 11:29:04.045132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yramakrishna/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2023-04-20 11:29:04.045135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dda329f-efda-445e-a58c-1a87f8ad2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file  = '/home/yramakrishna/DeepLabCut/conda-environments/Codes/Ken_Test_Long.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05155ca-d7ec-48ff-a5f5-0ddf682ea5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  WARNING: library configuration mismatch\n",
      "  avcodec     configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared --enable-version3 --disable-doc --disable-programs --enable-libaribb24 --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libtesseract --enable-libvo_amrwbenc --enable-libsmbclient\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/yramakrishna/DeepLabCut/conda-environments/Codes/Ken_Test_Long.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    creation_time   : 2023-01-12T16:13:31.000000Z\n",
      "  Duration: 00:07:22.91, start: 0.000000, bitrate: 8126 kb/s\n",
      "  Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 102 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-01-12T16:13:31.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720, 8018 kb/s, SAR 1:1 DAR 16:9, 29.97 fps, 29.97 tbr, 30k tbn, 60k tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-01-12T16:13:31.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5594804f9700] using SAR=4/3\n",
      "[libx264 @ 0x5594804f9700] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5594804f9700] profile High, level 1.3, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5594804f9700] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=7 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/yramakrishna/DeepLabCut/conda-environments/Codes/Ken_Test_Longdownsampled.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 320x240 [SAR 4:3 DAR 16:9], q=2-31, 29.97 fps, 30k tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-01-12T16:13:31.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 102 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-01-12T16:13:31.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "frame=13274 fps=1336 q=-1.0 Lsize=   13013kB time=00:07:22.90 bitrate= 240.7kbits/s speed=44.6x    \n",
      "video:6999kB audio:5539kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.791899%\n",
      "[libx264 @ 0x5594804f9700] frame I:55    Avg QP:21.32  size: 16010\n",
      "[libx264 @ 0x5594804f9700] frame P:3774  Avg QP:23.78  size:  1401\n",
      "[libx264 @ 0x5594804f9700] frame B:9445  Avg QP:30.52  size:   106\n",
      "[libx264 @ 0x5594804f9700] consecutive B-frames:  3.6%  2.8%  5.2% 88.4%\n",
      "[libx264 @ 0x5594804f9700] mb I  I16..4:  4.8% 40.0% 55.2%\n",
      "[libx264 @ 0x5594804f9700] mb P  I16..4:  0.7%  4.7%  1.3%  P16..4: 31.0%  9.5%  5.8%  0.0%  0.0%    skip:47.0%\n",
      "[libx264 @ 0x5594804f9700] mb B  I16..4:  0.0%  0.2%  0.0%  B16..8:  9.8%  0.8%  0.2%  direct: 0.5%  skip:88.5%  L0:41.6% L1:53.7% BI: 4.8%\n",
      "[libx264 @ 0x5594804f9700] 8x8 transform intra:65.4% inter:68.9%\n",
      "[libx264 @ 0x5594804f9700] coded y,uvDC,uvAC intra: 80.9% 88.0% 48.1% inter: 6.7% 9.3% 0.7%\n",
      "[libx264 @ 0x5594804f9700] i16 v,h,dc,p:  6% 40%  3% 51%\n",
      "[libx264 @ 0x5594804f9700] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 16%  9%  8%  8% 11%  8% 12% 10%\n",
      "[libx264 @ 0x5594804f9700] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 30% 10%  6%  7%  9%  6%  7%  6%\n",
      "[libx264 @ 0x5594804f9700] i8c dc,h,v,p: 45% 24% 19% 12%\n",
      "[libx264 @ 0x5594804f9700] Weighted P-Frames: Y:8.0% UV:5.2%\n",
      "[libx264 @ 0x5594804f9700] ref P L0: 64.0% 20.6%  9.7%  5.4%  0.3%\n",
      "[libx264 @ 0x5594804f9700] ref B L0: 92.8%  4.5%  2.7%\n",
      "[libx264 @ 0x5594804f9700] ref B L1: 97.0%  3.0%\n",
      "[libx264 @ 0x5594804f9700] kb/s:129.44\n"
     ]
    }
   ],
   "source": [
    "dsv = deeplabcut.DownSampleVideo(start_file, width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeda2adf-dc33-4685-97cb-8aa71535dacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "model = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(dsv)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Set the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "check = False\n",
    "frame_lum_val = []\n",
    "target_br = 0.6\n",
    "target_g = math.log(target_br)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Loop through the frames in the video\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    check = False\n",
    "    \n",
    "    # Check if the frame was successfully read\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Resize the frame to a smaller size (for faster processing)\n",
    "    small_frame = cv2.resize(frame, (300, 300))\n",
    "    \n",
    "    # Preprocess the frame for input to the neural network\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    # Pass the blob through the neural network to detect faces\n",
    "    model.setInput(blob)\n",
    "    detections = model.forward()\n",
    "    \n",
    "    # Loop through the detections and draw rectangles around the monkey faces\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:  # Only show faces with high confidence+\n",
    "            check = True\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            \n",
    "            #identify region around face\n",
    "            subframe = frame[startX:endX, startY:endY]\n",
    "            subframe_normalized = subframe.astype(np.float32) / 255.0\n",
    "            gray = cv2.cvtColor(subframe_normalized, cv2.COLOR_BGR2GRAY)\n",
    "            brightness = np.mean(gray)\n",
    "            \n",
    "            #finding and correcting gamma - a number is assigned to be the 'innate' gamma value of the frame, and that value is used to find the correction needed. \n",
    "            assigned_g = math.log(brightness)\n",
    "            gamma = assigned_g/target_g\n",
    "            \n",
    "            #implementing gamma correction\n",
    "            frame_normalized = frame.astype(np.float32) / 255.0\n",
    "            \n",
    "            frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "            \n",
    "            frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "            \n",
    "            # cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "    # cv2.imshow(\"Monkey faces\", frame_scaled)\n",
    "    if check:\n",
    "        out.write(frame_scaled)\n",
    "    \n",
    "    # Wait for a key press\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video file and close the window\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708dab8b-8edc-4b3f-93a7-748bc82d726d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_lum_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5d9b93-8d3f-46ff-afdf-60bbc79461c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cropping video and Gamma correction\n",
    "\n",
    "# # Load the video file\n",
    "# video = cv2.VideoCapture(dsv)\n",
    "\n",
    "# # Get the frame rate and total number of frames\n",
    "# fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "# total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# #*********************************************\n",
    "\n",
    "# # Set the start and end points to crop out\n",
    "# start_sec = 10  # Crop out the first x seconds\n",
    "# end_sec = 10 # Crop out the last y seconds\n",
    "\n",
    "# #Set gamma correction value\n",
    "# gamma = 2\n",
    "\n",
    "# #**********************************************\n",
    "\n",
    "# start_frame = int(start_sec * fps)\n",
    "# end_frame = int((total_frames / fps) - end_sec) * fps\n",
    "\n",
    "# # Set the video writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropGr.mp4', fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Set the current frame number to the start frame\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# # Loop through the frames and write them to the output video\n",
    "# for i in range(start_frame, end_frame):\n",
    "#     ret, frame = video.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     # Normalize the pixel values to the range [0, 1]\n",
    "#     frame_normalized = frame.astype(np.float32) / 255.0\n",
    "\n",
    "#     # Apply gamma correction\n",
    "#     frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "#     # Scale the pixel values back to the range [0, 255]\n",
    "#     frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "\n",
    "#     out.write(frame_scaled)\n",
    "\n",
    "# # Release the video objects\n",
    "# video.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f392891f-3388-467f-8f53-ac04fc00cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"final_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2c79ca-9bdb-4e2b-8c2e-867387ae2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final_video/CropGr.mp4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.move('CropGr.mp4', 'final_video/CropGr.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6fa656-4809-4010-895e-7578d26eb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('final_video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32119dff-6ecf-4cb8-b64c-82640c8bf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsv = deeplabcut.DownSampleVideo(start_file, width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386bb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file = 'CropGr.mp4'\n",
    "bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "             'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "video_down = file\n",
    "\n",
    "model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "model_selection = 'primate_face'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490386f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/labeled-data\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/training-datasets\"\n",
      "Created \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/dlc-models\"\n",
      "1  videos from the directory . were added to the project.\n",
      "Copying the videos\n",
      "/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4\n",
      "Generated \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/config.yaml\"\n",
      "\n",
      "A new project with name DLC_GazeXBI-anc-2023-04-20 is created at /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Downloading weights...\n",
      "Loading.... primate_face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afdadb384884a29b6191e273101d94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n-1_shuffle-1.tar.gz:   0%|          | 0.00/198M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/dlc-models/iteration-0/DLC_GazeXBIApr20-trainset95shuffle1/train/pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-1030000 for model /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/dlc-models/iteration-0/DLC_GazeXBIApr20-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yramakrishna/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-04-20 11:33:16.986062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:16.986806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:16.986937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:16.987375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 11:33:16.988196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:16.988343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:16.988465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:17.713906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:17.714068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:17.714188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 11:33:17.714275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13309 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:51:00.0, compute capability: 8.9\n",
      "2023-04-20 11:33:17.731030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4\n",
      "Loading  /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4\n",
      "Duration of video [s]:  160.14 , recorded with  29.0 fps!\n",
      "Overall # of frames:  4644  found with (before cropping) frame dimensions:  320 240\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/4644 [00:00<?, ?it/s]2023-04-20 11:33:18.892057: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2023-04-20 11:33:19.184356: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████████████████████████████████| 4644/4644 [00:10<00:00, 454.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    }
   ],
   "source": [
    "project_name = 'DLC_GazeXBI'\n",
    "your_name = 'anc'\n",
    "\n",
    "config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name,\n",
    "    your_name,\n",
    "    video_down,\n",
    "    videotype=videotype,\n",
    "    model=model_selection,\n",
    "    analyzevideo=True,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b47575-5bfd-4a6b-977a-f6e6692e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlc_model = config_path\n",
    "# dlc_config = deeplabcut.load_config(config_file)\n",
    "# dlc_model = deeplabcut.getModel(dlc_config)\n",
    "\n",
    "\n",
    "# # Load the video file\n",
    "# cap = cv2.VideoCapture(video_down)\n",
    "\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('CropMFace.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "# # Loop over each frame in the video\n",
    "# frame_count = 0\n",
    "# video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     # Break the loop when the video ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect the monkey face using the DeepLabCut model\n",
    "#     dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "#     monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "\n",
    "#     # Check if monkey face is detected in the frame\n",
    "#     if monkey_face_coordinates.any():\n",
    "#         out.write(frame_scaled)\n",
    "#         # Get the bounding box coordinates of the monkey face\n",
    "#         x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "\n",
    "#         # Crop out the monkey face and save it to a new file\n",
    "#         monkey_face = frame[y:y+h, x:x+w]\n",
    "#         cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "#         frame_count += 1\n",
    "\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# out.release()\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130ae6bb-1716-4997-a815-30f5978d3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7705e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4\n",
      "Saving filtered csv poses!\n",
      "Starting to process video: /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4\n",
      "Loading /home/yramakrishna/DeepLabCut/conda-environments/Codes/final_video/DLC_GazeXBI-anc-2023-04-20/videos/CropGr.mp4 and data.\n",
      "Duration of video [s]: 160.14, recorded with 29.0 fps!\n",
      "Overall # of frames: 4644 with cropped frame dimensions: 320 240\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4644/4644 [00:04<00:00, 1017.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits = {\n",
    "    'dotsize': 2,  # size of the dots!\n",
    "    'pcutoff': 0.4,  # the higher, the more conservative the plotting!\n",
    "}\n",
    "deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "\n",
    "project_path = os.path.dirname(config_path)\n",
    "full_video_path = os.path.join(\n",
    "    project_path,\n",
    "    'videos',\n",
    "    os.path.basename(video_down),\n",
    ")\n",
    "\n",
    "# filter predictions (should already be done above ;):\n",
    "deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype, )\n",
    "\n",
    "# re-create the video with your edits!\n",
    "# deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "\n",
    "deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True, filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4b348-6111-4710-b4c1-33911593d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # Load tracking results generated by DeepLabCut\n",
    "# tracking_data = pd.read_hdf('path/to/tracking_results.h5')\n",
    "\n",
    "# # Define the names of the facial features that you want to extract frames for\n",
    "# feature_names = ['face', 'nose', 'eye']\n",
    "\n",
    "# # Define the threshold for the confidence score of the facial features\n",
    "# confidence_threshold = 0.9\n",
    "\n",
    "# # Load the input video\n",
    "# cap = cv2.VideoCapture('path/to/input_video.mp4')\n",
    "\n",
    "# # Define the output video writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('path/to/output_video.mp4', fourcc, 30, (640, 480))\n",
    "\n",
    "# # Loop through the video frames and extract frames with facial features\n",
    "# frame_number = 0\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret == True:\n",
    "#         # Get the tracking data for the current frame\n",
    "#         frame_data = tracking_data.loc[frame_number]\n",
    "\n",
    "#         # Check if the desired facial features are present in the frame\n",
    "#         feature_present = False\n",
    "#         for feature_name in feature_names:\n",
    "#             if feature_name in frame_data and frame_data[feature_name]['likelihood'] > confidence_threshold:\n",
    "#                 feature_present = True\n",
    "#                 break\n",
    "\n",
    "#         # If the desired facial features are present, save the frame to the output video\n",
    "#         if feature_present:\n",
    "#             out.write(frame)\n",
    "\n",
    "#         # Display the output\n",
    "#         cv2.imshow('output', frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#         # Increment the frame number\n",
    "#         frame_number += 1\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# # Release resources\n",
    "# cap.release()\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdf6ca-a6b2-4b43-adc8-38a0091ad2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move('/home/yramakrishna/DeepLabCut/conda-environments/final_video/DLC_GazeXBI-anc-2023-03-28/videos/CropGrDLC_resnet50_DLC_GazeXBIMar28shuffle1_1030000_filtered_labeled.mp4', '/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar28shuffle1_1030000_filtered_labeled.mp4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f6e7-0077-4abc-a815-00912e48cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('/home/yramakrishna/DeepLabCut/conda-environments/final_video')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4314b3-5e42-4de8-b333-ccebc4245872",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('/home/yramakrishna/DeepLabCut/conda-environments/Ken_Test_Longdownsampled.mp4')\n",
    "except OSError as e:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511066-14c1-44d0-9566-9a2975babd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\")\n",
    "# ret, frame = cap.read()\n",
    "# while(1):\n",
    "#    ret, frame = cap.read()\n",
    "#    cv2.imshow('frame',frame)\n",
    "#    if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
    "#        cap.release()\n",
    "#        cv2.destroyAllWindows()\n",
    "#        break\n",
    "#    cv2.imshow('frame',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfab5c-99f8-427b-9bb0-634efbe8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import *\n",
    "# import pygame\n",
    " \n",
    "# clip = VideoFileClip('/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4')\n",
    "# clip.preview()\n",
    " \n",
    "# pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e155ed-c842-4f01-ba18-e0d6b38fafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkVideoPlayer import TkinterVideo\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "videoplayer = TkinterVideo(master=root, scaled=True)\n",
    "videoplayer.load(r\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar28shuffle1_1030000_filtered_labeled.mp4\")\n",
    "videoplayer.pack(expand=True, fill=\"both\")\n",
    "\n",
    "videoplayer.play() # play the video\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c14e94-b374-4c21-abce-0af196dfb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter import *\n",
    "# from tkvideo import tkvideo\n",
    "\n",
    "# root = Tk()\n",
    "# my_label = Label(root)\n",
    "# my_label.pack()\n",
    "# player = tkvideo(\"/home/yramakrishna/DeepLabCut/conda-environments/CropGrDLC_resnet50_DLC_GazeXBIMar20shuffle1_1030000_filtered_labeled.mp4\", my_label, loop = 1, size = (1280,720))\n",
    "# player.play()\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b60d65-a764-415f-8f9e-037d4941d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import deeplabcut\n",
    "\n",
    "# Load the DeepLabCut model\n",
    "config_file = 'path/to/config.yaml'\n",
    "dlc_model = deeplabcut.load_model(config_file)\n",
    "\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture('path/to/video')\n",
    "\n",
    "# Loop over each frame in the video\n",
    "frame_count = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Break the loop when the video ends\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect the monkey face using the DeepLabCut model\n",
    "    dlc_coordinates, _ = dlc_model.predict(frame, tracking=True)\n",
    "    monkey_face_coordinates = dlc_coordinates['monkey_face']\n",
    "    \n",
    "    # Check if monkey face is detected in the frame\n",
    "    if monkey_face_coordinates.any():\n",
    "        # Get the bounding box coordinates of the monkey face\n",
    "        x, y, w, h = cv2.boundingRect(monkey_face_coordinates.astype(int))\n",
    "        \n",
    "        # Crop out the monkey face and save it to a new file\n",
    "        monkey_face = frame[y:y+h, x:x+w]\n",
    "        cv2.imwrite(f'monkey_face_{frame_count}.jpg', monkey_face)\n",
    "        frame_count += 1\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170f049-3dec-4532-b55b-87f650ead785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "input_file = \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/All_vids/Videos/ken_20210506_XBI19_reversal_learning_foraging_SC3_DCS_frontcamera.mov\"\n",
    "output_file = \"/home/yramakrishna/DeepLabCut/conda-environments/Codes/All_vids/Conv_vids/CONVoutput.mp4\"\n",
    "\n",
    "# Run FFmpeg command to convert MOV to MP4\n",
    "command = f\"ffmpeg -i {input_file} -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k {output_file}\"\n",
    "subprocess.call(command, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
